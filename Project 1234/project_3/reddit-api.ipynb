{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Using Reddit's API, we have collected posts from two subreddits:\n",
    "* Technology\n",
    "* Today I Learned (TIL)\n",
    "\n",
    "Then we will use NLP to train a classifier on which subreddit a given post came from (A binary classification problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you get started, we have a primer video on how to use Reddit's API: https://www.youtube.com/watch?v=5Y3ZE26Ciuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The subreddits URLs\n",
    "url = [\n",
    "    {'Title': 'todayilearned', 'url' = 'https://www.reddit.com/r/todayilearned.json'},\n",
    "    {'Title': 'technology', 'url' = 'https://www.reddit.com/r/technology.json'},\n",
    "]\n",
    "\n",
    "\n",
    "# Changing the default user to ensure access to Reddit's \n",
    "res = requests.get(url1, headers={'User-agent': 'Pony Inc 1.0'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reddit knows that you are using a Chrome browser on a Mac is trying to access the address https://www.reddit.com/r/boardgames.json However, Python has its own default user agent. Since there are so many scripts out there that are already 'hitting' reddit's API, reddit is basically shutting down all Python scripts from accessing its API.\n",
    "\n",
    "We will change our request a little bit to make it not use the default user agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_dict = res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dictionary structure of reddit_dict\n",
    "\n",
    "reddit_dict = {\n",
    "    kind:,\n",
    "    data: {\n",
    "        modhash:, \n",
    "        dist:, \n",
    "        children:{ # has 26 elements\n",
    "            approved_at_utc:, \n",
    "            subreddit:,  #The cell directly above gives you the class label, aka your target.\n",
    "            selftext:,   #Mapping to the first post\n",
    "            author_fullname:, \n",
    "            saved:, \n",
    "            mod_reason_title:, \n",
    "            gilded:, \n",
    "            clicked:, \n",
    "            title:,  # The title of the post.\n",
    "            link_flair_richtext:, \n",
    "            subreddit_name_prefixed:, \n",
    "            hidden:, \n",
    "            pwls:, \n",
    "            link_flair_css_class:, \n",
    "            downs:, \n",
    "            thumbnail_height:, \n",
    "            hide_score:, \n",
    "            name:, \n",
    "            quarantine:, \n",
    "            link_flair_text_color:, \n",
    "            author_flair_background_color:, \n",
    "            subreddit_type:, \n",
    "            ups:, \n",
    "            total_awards_received:, \n",
    "            media_embed:, \n",
    "            thumbnail_width:, \n",
    "            author_flair_template_id:, \n",
    "            is_original_content:, \n",
    "            user_reports:, \n",
    "            secure_media:, \n",
    "            is_reddit_media_domain:, \n",
    "            is_meta:, \n",
    "            category:, \n",
    "            secure_media_embed:, \n",
    "            link_flair_text:, \n",
    "            can_mod_post:, \n",
    "            score:, \n",
    "            approved_by:, \n",
    "            thumbnail:, \n",
    "            edited:, \n",
    "            author_flair_css_class:, \n",
    "            author_flair_richtext:, \n",
    "            gildings:, \n",
    "            post_hint:, \n",
    "            content_categories:, \n",
    "            is_self:, \n",
    "            mod_note:, \n",
    "            created:, \n",
    "            link_flair_type:, \n",
    "            wls:, \n",
    "            banned_by:, \n",
    "            author_flair_type:, \n",
    "            domain:, \n",
    "            selftext_html:, \n",
    "            likes:, \n",
    "            suggested_sort:, \n",
    "            banned_at_utc:, \n",
    "            view_count:, \n",
    "            archived:, \n",
    "            no_follow:, \n",
    "            is_crosspostable:, \n",
    "            pinned:, \n",
    "            over_18:, \n",
    "            preview:, \n",
    "            all_awardings:, \n",
    "            media_only:, \n",
    "            can_gild:, \n",
    "            spoiler:, \n",
    "            locked:, \n",
    "            author_flair_text:, \n",
    "            visited:, \n",
    "            num_reports:, \n",
    "            distinguished:, \n",
    "            subreddit_id:, \n",
    "            mod_reason_by:, \n",
    "            removal_reason:, \n",
    "            link_flair_background_color:, \n",
    "            id:, \n",
    "            is_robot_indexable:, \n",
    "            report_reasons:, \n",
    "            author:, \n",
    "            num_crossposts:, \n",
    "            num_comments:, \n",
    "            send_replies:, \n",
    "            whitelist_status:, \n",
    "            contest_mode:, \n",
    "            mod_reports:, \n",
    "            author_patreon_flair:, \n",
    "            author_flair_text_color:, \n",
    "            permalink:, \n",
    "            parent_whitelist_status:, \n",
    "            stickied:, \n",
    "            url:, \n",
    "            subreddit_subscribers:, \n",
    "            created_utc:, \n",
    "            media:, \n",
    "            is_video:            \n",
    "        },\n",
    "        after:, \n",
    "        before:\n",
    "    }\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_dict['data'].keys() #The most important keys are children and after.\n",
    "reddit_dict['data']['children'][0]['data']['selftext'] #That's mapping to the first post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_by2qyg'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = [p['data'] for p in reddit_dict['data']['children']] #We want to get all these posts into a Pandas DataFrame and thereafter we can save it to a CSV.\n",
    "\n",
    "pd.DataFrame(posts)\n",
    "\n",
    "pd.DataFrame(posts).to_csv('posts.csv')\n",
    "\n",
    "reddit_dict['data']['after'] #This is the name of the last post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_dict['data']['before']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the name of the last post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     t3_by138z\n",
       "1     t3_by2u5q\n",
       "2     t3_by3iw1\n",
       "3     t3_bxzaff\n",
       "4     t3_by25jg\n",
       "5     t3_bxxyhl\n",
       "6     t3_by2vxh\n",
       "7     t3_bxxc4t\n",
       "8     t3_bxvy3m\n",
       "9     t3_by0o2l\n",
       "10    t3_by36j9\n",
       "11    t3_by2znc\n",
       "12    t3_by2wbz\n",
       "13    t3_by2s0f\n",
       "14    t3_by3msj\n",
       "15    t3_bxxflh\n",
       "16    t3_bxzog4\n",
       "17    t3_by4pqu\n",
       "18    t3_bxyic5\n",
       "19    t3_by36n3\n",
       "20    t3_by4sog\n",
       "21    t3_bxyd6v\n",
       "22    t3_by5529\n",
       "23    t3_by2qyg\n",
       "24    t3_by26eg\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(posts)['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_by26eg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_dict['data']['after']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the new URL that gives you the next 25 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.reddit.com/r/boardgames.json?after=t3_bxkt6m'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url + '?after=' + reddit_dict['data']['after'] #This is the new URL that gives you the next 25 posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through the posts, 25 posts at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/boardgames.json\n",
      "4\n",
      "https://www.reddit.com/r/boardgames.json?after=t3_bxkt6m\n",
      "5\n",
      "https://www.reddit.com/r/boardgames.json?after=t3_bxbxr2\n",
      "3\n",
      "https://www.reddit.com/r/boardgames.json?after=t3_bx4i0s\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "after = None\n",
    "\n",
    "for a in range(20):\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "    else:\n",
    "        current_url = url + '?after=' + after\n",
    "    print(current_url)\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "    \n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    # generate a random sleep duration to look more 'natural'\n",
    "    sleep_duration = random.randint(2,6)\n",
    "    print(str(a))\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/todayilearned.json\n",
      "0\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_by2qyg\n",
      "1\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxye8y\n",
      "2\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_by5zzt\n",
      "3\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_by22xl\n",
      "4\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxx7m4\n",
      "5\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_by10l4\n",
      "6\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxgrjm\n",
      "7\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxhw1v\n",
      "8\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxhh0h\n",
      "9\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxgkeb\n",
      "10\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxft79\n",
      "11\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxata2\n",
      "12\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxb6jr\n",
      "13\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bx3in4\n",
      "14\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bx8tki\n",
      "15\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bx86gl\n",
      "16\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bwxova\n",
      "17\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bww909\n",
      "18\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bwylor\n",
      "19\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bwonup\n",
      "20\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bwn6cm\n",
      "21\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bwlp9i\n",
      "22\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bw4ur2\n",
      "23\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bwfdwq\n",
      "24\n",
      "https://www.reddit.com/r/todayilearned.json\n",
      "25\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_by2qyg\n",
      "26\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxye8y\n",
      "27\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxqmnp\n",
      "28\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxxx31\n",
      "29\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxwohd\n",
      "30\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxxot3\n",
      "31\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxtk4f\n",
      "32\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxfyt6\n",
      "33\n",
      "https://www.reddit.com/r/todayilearned.json?after=t3_bxgdgv\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "after = None\n",
    "\n",
    "for a in range(35):\n",
    "    if after == None:\n",
    "        current_url = url1\n",
    "    else:\n",
    "        current_url = url1 + '?after=' + after\n",
    "    print(current_url)\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "    \n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    if a > 0:\n",
    "        prev_posts = pd.read_csv('boardgames.csv')\n",
    "        current_df = pd.DataFrame()\n",
    "        \n",
    "    else:\n",
    "        pd.DataFrame(posts).to_csv('boardgames.csv', index = False)\n",
    "\n",
    "    # generate a random sleep duration to look more 'natural'\n",
    "    sleep_duration = random.randint(2,6)\n",
    "    print(str(a))\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(posts).to_csv('boardgames.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
