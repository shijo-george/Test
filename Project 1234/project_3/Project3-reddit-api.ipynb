{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement\n",
    "\n",
    "Using Reddit's API, we have collected posts from two subreddits:\n",
    "* Casual Conversations\n",
    "* Board Games\n",
    "\n",
    "Then we will use NLP to train a classifier on which subreddit a given post came from (A binary classification problem).\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "Multinomial Naive Bayes with TFIDF gave the best accuracy score of 96.03%\n",
    "\n",
    "The other techniques used include:\n",
    "1. Logistic Regression\n",
    "2. Multinomial Naive Bayes:\n",
    "3. RandomForest methods.\n",
    "4. Ensemble techniques to optimize the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get the Reddit posts\n",
    "\n",
    "Initialize the URLs of the selected Reddits and specify the counts of iterations to be done for each reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The subreddits URLs\n",
    "url = pd.DataFrame([\n",
    "    ['casualconversation', 'https://www.reddit.com/r/casualconversation.json', 32],\n",
    "    ['boardgames', 'https://www.reddit.com/r/boardgames.json', 38],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 The dictionary structure of reddit_dict\n",
    "\n",
    "reddit_dict = {\n",
    "    kind:,\n",
    "    data: {\n",
    "        modhash:, \n",
    "        dist:, \n",
    "        children:{ # has 26 elements\n",
    "            approved_at_utc:, \n",
    "            subreddit:,  #The cell directly above gives you the class label, aka your target.\n",
    "            selftext:,   #Mapping to the first post\n",
    "            author_fullname:, \n",
    "            saved:, \n",
    "            mod_reason_title:, \n",
    "            gilded:, \n",
    "            clicked:, \n",
    "            title:,  # The title of the post.\n",
    "            link_flair_richtext:, \n",
    "            subreddit_name_prefixed:, \n",
    "            hidden:, \n",
    "            pwls:, \n",
    "            link_flair_css_class:, \n",
    "            downs:, \n",
    "            thumbnail_height:, \n",
    "            hide_score:, \n",
    "            name:, \n",
    "            quarantine:, \n",
    "            link_flair_text_color:, \n",
    "            author_flair_background_color:, \n",
    "            subreddit_type:, \n",
    "            ups:, \n",
    "            total_awards_received:, \n",
    "            media_embed:, \n",
    "            thumbnail_width:, \n",
    "            author_flair_template_id:, \n",
    "            is_original_content:, \n",
    "            user_reports:, \n",
    "            secure_media:, \n",
    "            is_reddit_media_domain:, \n",
    "            is_meta:, \n",
    "            category:, \n",
    "            secure_media_embed:, \n",
    "            link_flair_text:, \n",
    "            can_mod_post:, \n",
    "            score:, \n",
    "            approved_by:, \n",
    "            thumbnail:, \n",
    "            edited:, \n",
    "            author_flair_css_class:, \n",
    "            author_flair_richtext:, \n",
    "            gildings:, \n",
    "            post_hint:, \n",
    "            content_categories:, \n",
    "            is_self:, \n",
    "            mod_note:, \n",
    "            created:, \n",
    "            link_flair_type:, \n",
    "            wls:, \n",
    "            banned_by:, \n",
    "            author_flair_type:, \n",
    "            domain:, \n",
    "            selftext_html:, \n",
    "            likes:, \n",
    "            suggested_sort:, \n",
    "            banned_at_utc:, \n",
    "            view_count:, \n",
    "            archived:, \n",
    "            no_follow:, \n",
    "            is_crosspostable:, \n",
    "            pinned:, \n",
    "            over_18:, \n",
    "            preview:, \n",
    "            all_awardings:, \n",
    "            media_only:, \n",
    "            can_gild:, \n",
    "            spoiler:, \n",
    "            locked:, \n",
    "            author_flair_text:, \n",
    "            visited:, \n",
    "            num_reports:, \n",
    "            distinguished:, \n",
    "            subreddit_id:, \n",
    "            mod_reason_by:, \n",
    "            removal_reason:, \n",
    "            link_flair_background_color:, \n",
    "            id:, \n",
    "            is_robot_indexable:, \n",
    "            report_reasons:, \n",
    "            author:, \n",
    "            num_crossposts:, \n",
    "            num_comments:, \n",
    "            send_replies:, \n",
    "            whitelist_status:, \n",
    "            contest_mode:, \n",
    "            mod_reports:, \n",
    "            author_patreon_flair:, \n",
    "            author_flair_text_color:, \n",
    "            permalink:, \n",
    "            parent_whitelist_status:, \n",
    "            stickied:, \n",
    "            url:, \n",
    "            subreddit_subscribers:, \n",
    "            created_utc:, \n",
    "            media:, \n",
    "            is_video:            \n",
    "        },\n",
    "        after:, \n",
    "        before:\n",
    "    }\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Function to read through a given reddit and return the number of posts based on the specified iteration counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to read the reddit posts\n",
    "def read_reddit(url1, subreddit_name, iterations_range):\n",
    "\n",
    "    posts = []\n",
    "    after = None\n",
    "\n",
    "    for a in range(iterations_range):\n",
    "        if after == None:\n",
    "            current_url = url1\n",
    "        else:\n",
    "            current_url = url1 + '?after=' + after\n",
    "       \n",
    "        res = requests.get(current_url, headers={'User-agent': 'Pink Inc 1.0'})\n",
    "\n",
    "        if res.status_code != 200:\n",
    "            print('Status error', res.status_code)\n",
    "            break\n",
    "\n",
    "        current_dict = res.json()\n",
    "        current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "        posts.extend(current_posts)\n",
    "        after = current_dict['data']['after']\n",
    "\n",
    "        if a > 0:\n",
    "            prev_posts = pd.read_csv(subreddit_name + '.csv')\n",
    "            current_df = pd.DataFrame()\n",
    "            pd.DataFrame(posts).to_csv(subreddit_name + '.csv', index = False)\n",
    "        else:\n",
    "            pd.DataFrame(posts).to_csv(subreddit_name + '.csv', index = False)\n",
    "\n",
    "        if a % 10 == 0:\n",
    "            print(str(a) + \" iterations done\")\n",
    "\n",
    "        # Be a good internet citizen and generate a random sleep duration and not overload the Reddit servers\n",
    "        time.sleep(1)\n",
    "\n",
    "    return posts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Save reddit posts\n",
    "\n",
    "Save the dataframe of reddit posts into a .csv file as per the name given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_reddit(posts, subreddit_name):\n",
    "    pd.DataFrame(posts).to_csv(subreddit_name + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Call the functions to read and save the reddit posts\n",
    "\n",
    "Also check if the post entries are unique based on the 'name' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iterations done\n",
      "10 iterations done\n",
      "20 iterations done\n",
      "30 iterations done\n",
      "\n",
      "797 Unique posts stored for reddit: casualconversation\n",
      "0 iterations done\n",
      "10 iterations done\n",
      "20 iterations done\n",
      "30 iterations done\n",
      "\n",
      "946 Unique posts stored for reddit: boardgames\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    reddit_posts = read_reddit(url.iloc[i][1], url.iloc[i][0], url.iloc[i][2])\n",
    "    \n",
    "    if len(set(pd.DataFrame(reddit_posts)['name'])) == len(reddit_posts):\n",
    "        store_reddit( reddit_posts, url.iloc[i][0])\n",
    "    \n",
    "        print(\"\\n\" + str(len(reddit_posts)) + \" Unique posts stored for reddit: \"+ url.iloc[i][0])\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n\" + str(len(set(pd.DataFrame(reddit_posts)['name']))) + \" Unique posts stored for reddit: \"+ url.iloc[i][0])\n",
    "        print(str(len(reddit_posts)) + \" Total posts stored for reddit: \"+ url.iloc[i][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Convert the reddit posts into dataframes and do a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from both subreddits\n",
    "reddit_posts1 = pd.read_csv(url.iloc[0][0] + '.csv')\n",
    "reddit_posts2 = pd.read_csv(url.iloc[1][0] + '.csv')\n",
    "\n",
    "reddit_posts1.dropna(subset=['title','selftext'],inplace=True)\n",
    "reddit_posts2.dropna(subset=['title','selftext'],inplace=True)\n",
    "\n",
    "# Create X data frame with data from both the subreddits\n",
    "X = pd.DataFrame(reddit_posts1[['title','selftext']])\n",
    "X = X.append(reddit_posts2[['title','selftext']])\n",
    "\n",
    "# Create feature \"text\" in X which contains lowercase text from the reddit title and posts. \n",
    "X['text'] = X['title'] + X['selftext']\n",
    "X['text'].str.lower()\n",
    "X = X['text'].str.lower()\n",
    "\n",
    "# Create y data frame with data from both the subreddits\n",
    "y = pd.DataFrame(reddit_posts1[[\"subreddit\"]])\n",
    "y = y.append(reddit_posts2[[\"subreddit\"]])\n",
    "\n",
    "# Create feature \"target\" in Y which is the target value\n",
    "y['subreddit'] = y['subreddit'].apply(lambda X:1 if X==url.iloc[1][0] else 0)\n",
    "\n",
    "\n",
    "# perform train/test split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=y['subreddit'], random_state=42, test_size=.2)\n",
    "\n",
    "\n",
    "# vect = CountVectorizer(stop_words=\"english\")\n",
    "# vect.fit(X['text'].values.astype('U'))\n",
    "\n",
    "# # Instantiate tokenizer.\n",
    "# tokenizer = RegexpTokenizer('[a-z]\\w+')\n",
    "\n",
    "\n",
    "# # Run tokenizer.\n",
    "# tokenizer.tokenize(s)\n",
    "\n",
    "# dicti = vect.vocabulary_\n",
    "\n",
    "# with open('file10.txt', 'bx') as file:\n",
    "#     file.write(str(dicti).encode(\"utf-8\"))\n",
    "    \n",
    "# # Read the file\n",
    "# f = open('file10.txt','r', encoding=\"utf8\")\n",
    "\n",
    "# # Read file into string\n",
    "# s = f.read()\n",
    "\n",
    "# # Split string using delimiter - in my case it was comma. Change as needed\n",
    "# my_list = s.split(',')\n",
    "\n",
    "# print(len(my_list))\n",
    "# # Convert list into dataframe and write it into a csv file\n",
    "\n",
    "# pd.DataFrame(my_list).to_csv(\"file11.csv\")\n",
    "\n",
    "# #pd.DataFrame(vect.vocabulary_).to_csv(\"vect\" + '.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Text processing and EDA\n",
    "\n",
    "## 4.1 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NA rows deleted in Casual Conversations = 1\n",
    "NA rows deleted in boardgames =  106\n",
    "Baseline word count = 16521\n",
    "After removal of stop words = 16228\n",
    "After changing all to lowercase = 16228\n",
    "After retaining only the alphabetic text = 13049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Function to Display Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_wordcount(subreddit_df, iterations_range):\n",
    "    corpus_string = ''\n",
    "\n",
    "    for i in range(iterations_range):\n",
    "    corpus_string = corpus_string + subreddit_df.iloc[i]['text']\n",
    "\n",
    "\n",
    "    mycloud_2 = WordCloud(width=1000, height=1000,\n",
    "                    collocations=False, #get rid of duplicates\n",
    "                   normalize_plurals=True).generate_from_text(corpus_string)\n",
    "\n",
    "    plt.figure(figsize = (10, 10), facecolor = None)\n",
    "    plt.imshow(mycloud_2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 CountVectorize and transform the train and the test data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13049\n",
      "(1308, 13049)\n",
      "(328, 13049)\n"
     ]
    }
   ],
   "source": [
    "cvec = CountVectorizer(lowercase=True, token_pattern='[a-z]\\w+', stop_words=ENGLISH_STOP_WORDS)\n",
    "cvec.fit(X_train)\n",
    "print(len(cvec.get_feature_names()))\n",
    "#print(cvec.get_feature_names())\n",
    "X_train_cv = pd.DataFrame(cvec.transform(X_train).todense(),columns=cvec.get_feature_names())\n",
    "X_test_cv = pd.DataFrame(cvec.transform(X_test).todense(),columns=cvec.get_feature_names())\n",
    "\n",
    "print(X_train_cv.shape)\n",
    "print(X_test_cv.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Modeling\n",
    "\n",
    "## 5.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9542682926829268\n",
      "accuracy score 0.9542682926829268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9542682926829268\n",
      "accuracy score 0.9542682926829268\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_cv, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_cv)\n",
    "\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))\n",
    "print('accuracy score',lr.score(X_test_cv, y_test))\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_cv, y_train)\n",
    "y_pred = lr.predict(X_test_cv)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))\n",
    "print('accuracy score',lr.score(X_test_cv, y_test))\n",
    "\n",
    "#columns\n",
    "columns=cvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Analyzing Keywords via Beta Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>1.968815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boardgame</th>\n",
       "      <td>1.110741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>games</th>\n",
       "      <td>1.039157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>board</th>\n",
       "      <td>0.962355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>0.948913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>copy</th>\n",
       "      <td>0.888411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cards</th>\n",
       "      <td>0.854315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabletop</th>\n",
       "      <td>0.821358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kickstarter</th>\n",
       "      <td>0.765846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buying</th>\n",
       "      <td>0.735457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>0.732173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>box</th>\n",
       "      <td>0.665495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player</th>\n",
       "      <td>0.662898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worth</th>\n",
       "      <td>0.655148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <td>0.639832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rulebook</th>\n",
       "      <td>0.630452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanks</th>\n",
       "      <td>0.586386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dice</th>\n",
       "      <td>0.565459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rules</th>\n",
       "      <td>0.563570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playing</th>\n",
       "      <td>0.550368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bought</th>\n",
       "      <td>0.539053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rule</th>\n",
       "      <td>0.510167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clue</th>\n",
       "      <td>0.496009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0.493310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catan</th>\n",
       "      <td>0.492994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clever</th>\n",
       "      <td>0.473425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>th</th>\n",
       "      <td>0.470176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking</th>\n",
       "      <td>0.469954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy</th>\n",
       "      <td>0.461912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minis</th>\n",
       "      <td>0.447218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-0.435072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps4</th>\n",
       "      <td>-0.436026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>-0.438753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>-0.441698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>-0.447801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep</th>\n",
       "      <td>-0.456531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goes</th>\n",
       "      <td>-0.462582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>-0.467792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stuff</th>\n",
       "      <td>-0.468647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc</th>\n",
       "      <td>-0.475643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>-0.479440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social</th>\n",
       "      <td>-0.484185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let</th>\n",
       "      <td>-0.519767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weird</th>\n",
       "      <td>-0.522591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watching</th>\n",
       "      <td>-0.523032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tell</th>\n",
       "      <td>-0.529268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>-0.547655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commercial</th>\n",
       "      <td>-0.555511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birthday</th>\n",
       "      <td>-0.559675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>-0.586296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days</th>\n",
       "      <td>-0.590655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>-0.606187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>-0.609343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone</th>\n",
       "      <td>-0.634881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>-0.669087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>-0.679654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk</th>\n",
       "      <td>-0.727987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>-0.751539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>-0.782154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>-0.852593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13049 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "game         1.968815\n",
       "boardgame    1.110741\n",
       "games        1.039157\n",
       "board        0.962355\n",
       "play         0.948913\n",
       "copy         0.888411\n",
       "cards        0.854315\n",
       "tabletop     0.821358\n",
       "kickstarter  0.765846\n",
       "buying       0.735457\n",
       "com          0.732173\n",
       "box          0.665495\n",
       "player       0.662898\n",
       "worth        0.655148\n",
       "table        0.639832\n",
       "rulebook     0.630452\n",
       "thanks       0.586386\n",
       "dice         0.565459\n",
       "rules        0.563570\n",
       "playing      0.550368\n",
       "bought       0.539053\n",
       "rule         0.510167\n",
       "clue         0.496009\n",
       "missing      0.493310\n",
       "catan        0.492994\n",
       "clever       0.473425\n",
       "th           0.470176\n",
       "looking      0.469954\n",
       "enjoy        0.461912\n",
       "minis        0.447218\n",
       "...               ...\n",
       "like        -0.435072\n",
       "ps4         -0.436026\n",
       "movie       -0.438753\n",
       "went        -0.441698\n",
       "really      -0.447801\n",
       "sleep       -0.456531\n",
       "goes        -0.462582\n",
       "song        -0.467792\n",
       "stuff       -0.468647\n",
       "pc          -0.475643\n",
       "day         -0.479440\n",
       "social      -0.484185\n",
       "let         -0.519767\n",
       "weird       -0.522591\n",
       "watching    -0.523032\n",
       "tell        -0.529268\n",
       "work        -0.547655\n",
       "commercial  -0.555511\n",
       "birthday    -0.559675\n",
       "movies      -0.586296\n",
       "days        -0.590655\n",
       "video       -0.606187\n",
       "job         -0.609343\n",
       "phone       -0.634881\n",
       "feel        -0.669087\n",
       "think       -0.679654\n",
       "talk        -0.727987\n",
       "life        -0.751539\n",
       "reddit      -0.782154\n",
       "school      -0.852593\n",
       "\n",
       "[13049 rows x 1 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing Keywords via Beta Coefficients\n",
    "lr_coef = pd.DataFrame(lr.coef_, columns = columns)\n",
    "df_coef = lr_coef.T.sort_values(by = 0, ascending = False)\n",
    "df_coef\n",
    "\n",
    "# key word for boardgames:\n",
    "#   game; boardgame, games, baord, play, copy cards, tabletop, kickstarter, buying, box, player\n",
    "\n",
    "# key words for Casualconversations:\n",
    "#   school, reddit, life, talk, think, feel, phone, job, video, movies, birthday, work, tell, watching, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted casualconversation</th>\n",
       "      <th>predicted boardgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual casualconversation</th>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual boardgames</th>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           predicted casualconversation  predicted boardgames\n",
       "actual casualconversation                           152                     8\n",
       "actual boardgames                                     7                   161"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix:\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted casualconversation', 'predicted boardgames'], \n",
    "                     index=['actual casualconversation', 'actual boardgames'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    168\n",
       "0    160\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 TFIDF Vectorizer & Logistic Regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9542682926829268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = make_pipeline(TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS),\n",
    "                      LogisticRegression(),\n",
    "                      )\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Confusion matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted casualconversation</th>\n",
       "      <th>predicted boardgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual casualconversation</th>\n",
       "      <td>154</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual boardgames</th>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           predicted casualconversation  predicted boardgames\n",
       "actual casualconversation                           154                     6\n",
       "actual boardgames                                     9                   159"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix: \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted casualconversation', 'predicted boardgames'], \n",
    "                     index=['actual casualconversation', 'actual boardgames'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    168\n",
       "0    160\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Multinomial Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9542682926829268"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted casualconversation</th>\n",
       "      <th>predicted boardgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual casualconversation</th>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual boardgames</th>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           predicted casualconversation  predicted boardgames\n",
       "actual casualconversation                           152                     8\n",
       "actual boardgames                                     7                   161"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix: \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted casualconversation', 'predicted boardgames'], \n",
    "                     index=['actual casualconversation', 'actual boardgames'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    168\n",
       "0    160\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Multinomial Naive Bayes with TFIDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_tfidf = make_pipeline(TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS),\n",
    "                      nb)\n",
    "nb_tfidf.fit(X_train, y_train)\n",
    "y_pred = nb_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9603658536585366"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted casualconversation</th>\n",
       "      <th>predicted boardgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual casualconversation</th>\n",
       "      <td>151</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual boardgames</th>\n",
       "      <td>4</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           predicted casualconversation  predicted boardgames\n",
       "actual casualconversation                           151                     9\n",
       "actual boardgames                                     4                   164"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix: \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted casualconversation', 'predicted boardgames'], \n",
    "                     index=['actual casualconversation', 'actual boardgames'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Pipeline - Count Vectorizer & Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9542682926829268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# same as above but with a Pipeline:\n",
    "model = make_pipeline(CountVectorizer(stop_words=ENGLISH_STOP_WORDS),LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 RandomForest with CountVectorizer - Gridsearch Params + Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9115853658536586\n",
      "best cv score 0.8983180428134556\n",
      "test score 0.9115853658536586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "# same as above but with Gridsearch & pipeline:\n",
    "\n",
    "rf_model = make_pipeline(CountVectorizer(stop_words=ENGLISH_STOP_WORDS),\n",
    "                      RandomForestClassifier(n_estimators= 7, random_state = 42))\n",
    "#params={'n_estimators' : [5, 7, 10]}\n",
    "params={}\n",
    "gs= GridSearchCV(rf_model, param_grid=params)\n",
    "gs.fit(X_train, y_train)\n",
    "y_pred = gs.predict(X_test)\n",
    "#print('best params', gs.best_params_)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))\n",
    "print('best cv score', gs.best_score_)\n",
    "print('test score', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted casualconversation</th>\n",
       "      <th>predicted boardgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual casualconversation</th>\n",
       "      <td>148</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual boardgames</th>\n",
       "      <td>17</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           predicted casualconversation  predicted boardgames\n",
       "actual casualconversation                           148                    12\n",
       "actual boardgames                                    17                   151"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix: \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted casualconversation', 'predicted boardgames'], \n",
    "                     index=['actual casualconversation', 'actual boardgames'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Pipeline - RandomForest with TFIDFVectorizer & Gridsearch Params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.8810975609756098\n",
      "best cv score 0.8983180428134556\n",
      "test score 0.8810975609756098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shijo\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_model_2 = make_pipeline(TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS),\n",
    "                      RandomForestClassifier(n_estimators=7, random_state=42))\n",
    "#params={'n_estimators' : [5, 7, 10]}\n",
    "gs1= GridSearchCV(rf_model_2, param_grid=params)\n",
    "gs1.fit(X_train, y_train)\n",
    "y_pred = gs1.predict(X_test)\n",
    "print('accuracy score',accuracy_score(y_test, y_pred))\n",
    "print('best cv score', gs1.best_score_)\n",
    "print('test score', gs1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted casualconversation</th>\n",
       "      <th>predicted boardgames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual casualconversation</th>\n",
       "      <td>135</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual boardgames</th>\n",
       "      <td>14</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           predicted casualconversation  predicted boardgames\n",
       "actual casualconversation                           135                    25\n",
       "actual boardgames                                    14                   154"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix: \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted casualconversation', 'predicted boardgames'], \n",
    "                     index=['actual casualconversation', 'actual boardgames'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
